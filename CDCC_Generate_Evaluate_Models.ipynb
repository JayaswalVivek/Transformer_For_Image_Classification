{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2501d59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db24ae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import (Dataset,\n",
    "                      concatenate_datasets,\n",
    "                      Image,\n",
    "                      ClassLabel,)\n",
    "\n",
    "from PIL import Image as pil\n",
    "\n",
    "from transformers import (Swinv2Config,\n",
    "                          AutoImageProcessor,\n",
    "                          AutoModelForImageClassification,\n",
    "                          Trainer,\n",
    "                          TrainingArguments,)\n",
    "\n",
    "from torchvision.transforms import (\n",
    "                            Compose,\n",
    "                            RandomResizedCrop,\n",
    "                            CenterCrop,\n",
    "                            RandomRotation,\n",
    "                            ColorJitter,\n",
    "                            Normalize,\n",
    "                            Resize,\n",
    "                            ToTensor,\n",
    "                            ToPILImage,)\n",
    "\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1866dc",
   "metadata": {},
   "source": [
    "### Load and augment image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1240fd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run CDCC_Image_Classification_Func.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf1c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = '/Zindi_Crop_Classification/Data/Image_MetaData/{}'\n",
    "\n",
    "image_path = '/Zindi_Crop_Classification/Data/Raw_Images/{}'\n",
    "aug_image_path = '/Zindi_Crop_Classification/Data/Augmented_Images/{}'\n",
    "\n",
    "model_path = '/Zindi_Crop_Classification/Fine_Tuned_Models/{}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb22dd5",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0544e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mstr_frame = pd.read_csv(labels_path.format('Train.csv'))\n",
    "print(mstr_frame.shape)\n",
    "mstr_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf28188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unbalanced data set\n",
    "mstr_frame['damage'].value_counts()\n",
    "\n",
    "# damage\n",
    "# G        11623\n",
    "# WD        9238\n",
    "# DR        4516\n",
    "# other      419\n",
    "# ND         272\n",
    "# Name: count, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265ca19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = mstr_frame['damage'].value_counts().index.to_list()\n",
    "class_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9171e857",
   "metadata": {},
   "source": [
    "### Data augmentation (optional)\n",
    "<b> Generate additional images for the under-represented classes <br>\n",
    "<b> Consider geometric transformations, photometric transformations, or a combination thereof <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd616cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a05efbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training dataset\n",
    "trng_idx = select_indexes(5000, 0.7, mstr_frame)\n",
    "subset_labels = mstr_frame.iloc[trng_idx, :].copy()\n",
    "subset_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9adff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate validation dataset\n",
    "non_selected_idx = list(set(range(mstr_frame.shape[0])) - set(trng_idx))\n",
    "val_labels = mstr_frame.iloc[non_selected_idx, :].copy()\n",
    "\n",
    "val_idx = select_indexes(2000, 1, val_labels)\n",
    "subset_eval_labels = val_labels.iloc[val_idx, :].copy()\n",
    "subset_eval_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fc249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_img_size = 256 # Needed for RandomResizedCrop\n",
    "\n",
    "aug_transform = Compose(\n",
    "                [\n",
    "                    #RandomResizedCrop((aug_img_size, aug_img_size)),\n",
    "                    #ColorJitter((0.5, 2)),\n",
    "                    #ColorJitter(contrast=(0.5, 2)),\n",
    "                    RandomRotation(30),\n",
    "                    ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "topilImage = ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e0600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trng_dataset = generate_dataset(subset_labels, \n",
    "                                0, \n",
    "                                0, # Change this value if data augmentation needs to be performed, e.g. 1500\n",
    "                                aug_image_path.format('other/other_'),\n",
    "                                aug_image_path.format('ND/ND_'),\n",
    "                                True,\n",
    "                                'Trng',\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d783765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = generate_dataset(subset_eval_labels, \n",
    "                                0, # change this value if validation set should include augmented images, e.g. 1500\n",
    "                                0, # if the previous value is non-zero, then this should be previous value + number of images, e,g. 2000\n",
    "                                aug_image_path.format('other/other_'),\n",
    "                                aug_image_path.format('ND/ND_'),\n",
    "                                True,\n",
    "                                'Val',\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbda2f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels = trng_dataset.features['label'].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(data_labels):\n",
    "    label2id[label] = i\n",
    "    id2label[i] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fbe28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = trng_dataset.train_test_split(test_size=0.1)\n",
    "train_ds = splits['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e22bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_splits = val_dataset.train_test_split(test_size=0.1)\n",
    "val_ds = val_splits['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a12c670",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28f7c7f",
   "metadata": {},
   "source": [
    "### Model training and validation\n",
    "<b> Step 1: Resize all images to a fixed size <br>\n",
    "<b> Step 2: Initialize the model's parameters using the pretrained SwinV2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa22c618",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"microsoft/swinv2-tiny-patch4-window16-256\"\n",
    "batch_size = 12 #4 # batch size for training and evaluation\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d6747",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size = 256 \n",
    "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "\n",
    "img_transform = Compose(\n",
    "        [\n",
    "            Resize(crop_size),\n",
    "            ToTensor(), # scales an image so that each channel has values in the range [0, 1]\n",
    "            normalize,\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656cf4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'pixel_values' column on-the-fly\n",
    "train_ds.set_transform(preprocess_img)\n",
    "val_ds.set_transform(preprocess_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfcb24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a configuration with optional regularization\n",
    "swin_config = Swinv2Config(#image_size=center_crop_size,\n",
    "                        image_size=crop_size,\n",
    "                        #hidden_dropout_prob=0.1, \n",
    "                        #attention_probs_dropout_prob=0.1,\n",
    "                        label2id=label2id, # this is required to change the number of nodes in the output layer\n",
    "                        id2label=id2label, # this is required to change the number of nodes in the output layer\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0823fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_name,\n",
    "    ignore_mismatched_sizes = True, # this is required to change the number of nodes in the output layer\n",
    "    config=swin_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72ec6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prefix = model_name.split(\"/\")[-1] + '-CDCC'\n",
    "\n",
    "# Vary the learning rate and determine its impact on model's performance\n",
    "args = TrainingArguments(\n",
    "    model_path.format(model_prefix),\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=1e-5, #5e-5\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=40,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=image_processor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=img_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eafef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce68b226",
   "metadata": {},
   "source": [
    "### Prediction on Zindi's test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be7a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the best model obtained at the end of model training to 'Best_Model' folder\n",
    "\n",
    "ck_model_name = model_path.format('Best_Model')\n",
    "best_processor = AutoImageProcessor.from_pretrained(ck_model_name)\n",
    "best_model = AutoModelForImageClassification.from_pretrained(ck_model_name)\n",
    "best_processor.size = {'height': 256, 'width': 256}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d80dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame = pd.read_csv(labels_path.format('Test.csv'))\n",
    "print(test_frame.shape)\n",
    "test_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9db1024",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = test_frame.shape[0]\n",
    "test_logit = np.zeros(num_test_samples*5).reshape(-1, 5)\n",
    "\n",
    "for i in range(num_test_samples):\n",
    "    if i% 1000 == 0:\n",
    "        print(f'Test image number {i}')\n",
    "    test_img = pil.open(image_path.format(test_frame.iloc[i, 1])).convert('RGB')\n",
    "    encoding = best_processor(test_img, return_tensors=\"pt\")\n",
    "    out = best_model(**encoding)\n",
    "    test_logit[i, :] = out.logits.numpy(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2c2399",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels\n",
    "# ['G', 'WD', 'DR', 'other', 'ND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aa832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# order for submission - DR,G,ND,WD,other\n",
    "out_frame = pd.DataFrame(test_logit, columns=class_labels)\n",
    "out_frame['ID'] = test_frame['ID']\n",
    "sorted_frame = out_frame[['ID', 'DR','G', 'ND', 'WD', 'other']].copy()\n",
    "sorted_frame.to_csv('CDCC_Inference_2.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b8c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert logits to probabilities\n",
    "pred_logits = pd.read_csv('CDCC_Inference_2.csv')\n",
    "softmax_prob = softmax(pred_logits.iloc[:, 1:], axis=1)\n",
    "pred_logits.iloc[:, 1:] = softmax_prob # Overwrite the logits with probabilities\n",
    "pred_logits.to_csv('CDCC_Inference_Prob_2.csv', index=False, sep=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_3_8_Vision",
   "language": "python",
   "name": "python_3_8_vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
