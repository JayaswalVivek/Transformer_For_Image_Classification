{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d27561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_indexes(max_samples_per_class, trng_prob, in_frame):\n",
    "    selected_idx = []\n",
    "\n",
    "    for label in class_labels:\n",
    "        class_idx = np.where(in_frame['damage'] == label)[0]\n",
    "        num_samples = int(np.min([max_samples_per_class, len(class_idx)*trng_prob]))\n",
    "        sub_idx = rng.choice(class_idx, num_samples, replace=False).tolist()\n",
    "        selected_idx += sub_idx\n",
    "        \n",
    "    return selected_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46135ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(in_frame, start_idx, end_idx, other_path, nd_path, image_exist, save_suffix):\n",
    "\n",
    "    num_samples = in_frame.shape[0]\n",
    "    num_extra_images = end_idx - start_idx\n",
    "    \n",
    "    img_path, img_label = [], []\n",
    "    for i in range(num_samples):\n",
    "        img_path += [image_path.format(in_frame.iloc[i, 2])]\n",
    "        img_label += [in_frame.iloc[i, 1]]\n",
    "\n",
    "    dataset = Dataset.from_dict({\"image\":img_path, \"label\":img_label})\n",
    "    dataset = dataset.cast_column(\"image\", Image()) # by default decode = TRUE\n",
    "    dataset = dataset.cast_column(\"label\", ClassLabel(num_classes=5, names=class_labels, id=None))\n",
    "    \n",
    "    if num_extra_images==0:\n",
    "        return dataset\n",
    "    \n",
    "    if image_exist is False:\n",
    "        file_names = augment_data('other', in_frame, start_idx, num_extra_images)\n",
    "        pd.DataFrame(file_names).to_csv('Other-Augment-' + save_suffix +'.txt', index=False, sep=\",\")\n",
    "\n",
    "        file_names = augment_data('ND', in_frame, start_idx, num_extra_images)\n",
    "        pd.DataFrame(file_names).to_csv('ND-Augment-' + save_suffix +'.txt', index=False, sep=\",\")\n",
    "\n",
    "    other_images = [other_path + str(idx) + '.jpg' for idx in range(start_idx, end_idx)]\n",
    "    nd_images = [nd_path + str(idx) + '.jpg' for idx in range(start_idx, end_idx)]\n",
    "\n",
    "    other_labels = [3]*num_extra_images\n",
    "    nd_labels = [4]*num_extra_images\n",
    "\n",
    "    extra_images = other_images + nd_images\n",
    "    extra_labels = other_labels + nd_labels\n",
    "    \n",
    "    extra_dataset = Dataset.from_dict({'image':extra_images, 'label':extra_labels})\n",
    "    extra_dataset = extra_dataset.cast_column('image', Image())\n",
    "    extra_dataset = extra_dataset.cast_column('label', ClassLabel(num_classes=5, names=class_labels, id=None))\n",
    "    \n",
    "    final_dataset = concatenate_datasets([extra_dataset, dataset])\n",
    "    \n",
    "    return final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7770d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(class_type, in_frame, start_idx, num_extra_images):\n",
    "    class_idx = np.where(in_frame['damage'] == class_type)[0]\n",
    "    img_files = rng.choice(in_frame.iloc[class_idx, 2], num_extra_images)\n",
    "\n",
    "    for i in range(num_extra_images):\n",
    "        current_img_path = image_path.format(img_files[i])\n",
    "        img = pil.open(current_img_path)\n",
    "        mod_img = aug_transform(img)\n",
    "        rel_path = class_type + '/' + class_type + '_' + str(i+start_idx) + '.jpg'\n",
    "        topilImage(mod_img).save(aug_image_path.format(rel_path), quality=95)\n",
    "        \n",
    "    return img_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc398f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the compute_metrics function takes a Named Tuple as input:\n",
    "# predictions, which are the logits of the model as Numpy arrays,\n",
    "# and label_ids, which are the ground-truth labels as Numpy arrays.\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=eval_pred.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8913b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'batch' is a dictionary with each value being a list of elements\n",
    "def preprocess_img(batch):\n",
    "    batch[\"pixel_values\"] = [img_transform(image.convert(\"RGB\")) for image in batch[\"image\"]]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2106a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collators are objects that will form a batch by using a list of dataset elements as input\n",
    "def img_collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_3_8_Vision",
   "language": "python",
   "name": "python_3_8_vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
